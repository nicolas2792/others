{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-830d7266-e7f2-4f44-9f50-d9fb41bbe74b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Modelo de recomendaciones para vacantes de trabajo\n",
    "\n",
    "La idea de esta prueba técnica es poder construir un modelo sencillo para poder recomendar vacantes laborales a personas en búsqueda de empleo. \n",
    "\n",
    "Para ello vamos a trabajar la prueba en dos fases:\n",
    "1. Extracción y preparación de los datos que vayan a ser usados como input \n",
    "2. Construcción y ejecución del modelo que se proponga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-2539f7df-82bf-4405-aba6-594197d20635",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Fase 1: Extraccion y preparación de los datos\n",
    "\n",
    "En esta primera parte se requiere construir la base de datos que se usará para generar recomendaciones laborales. Para ello vamos a considerar dos fuentes de datos: \n",
    "\n",
    "1. Datos de personas buscando empleo\n",
    "2. Datos de vacantes de trabajo disponibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-28ab69ab-0e1f-43c6-b484-fc89e97154e1",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Datos de personas en búsqueda de empleo\n",
    "\n",
    "En este primer bloque de código debes traer los datos de las personas en busqueda laboral \n",
    "\n",
    "url = https://docs.google.com/spreadsheets/d/1O1N08D-5NnWjnKJ6LrU0hjbYjgN6BPrN1Cg1FWQ8Y4w/edit?usp=sharing\n",
    "\n",
    "**diccionario de columnas:**\n",
    "\n",
    "* `anonymous_user` : identificador de usuario anonimizado\n",
    "* `puestos_postulandose` : array() de los tipos de puestos a los que la persona desea aplicar\n",
    "* `subareas_trabajo` : array() de las areas de trabajo a las que la persona desea aplicar\n",
    "* `nivel_de_ingles` : nivel de ingles de la persona  \n",
    "\n",
    "Sigue la documentacion aquí como una posible guía para traer los datos desde el google sheets: \n",
    "\n",
    "[Como traer datos a pandas desde google sheets](https://towardsdatascience.com/read-data-from-google-sheets-into-pandas-without-the-google-sheets-api-5c468536550)\n",
    "\n",
    "al final asegurate de que el dataframe conteniendo la data de la personas se guarde como `personas_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-b98f5608-e631-4980-a157-2c8bd8bf0dbf",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1628565267246,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sheet_id=\"1O1N08D-5NnWjnKJ6LrU0hjbYjgN6BPrN1Cg1FWQ8Y4w\"\n",
    "sheet_name=\"raw_data\"\n",
    "base = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "\n",
    "personas_df=pd.read_csv(base)\n",
    "\n",
    "# elimino los registros que no tienen informaciòn ni en el puesto postulante ni en las subareas de trabajo\n",
    "\n",
    "personas_df=personas_df.dropna(subset=[\"puestos_postulandose\",\"subareas_trabajo\"], how='all')\n",
    "\n",
    "# ver si existes ususarios repetidos\n",
    "print(personas_df['anonymous_user'].duplicated().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-56fdca71-886c-4cf1-903a-80c390c1724f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Datos de las vacantes de trabajo disponibles\n",
    "\n",
    "En este segundo bloque de codigo debes implementar un proceso que traiga vacantes publicas disponibles de alguna fuente de datos relevante, e.j. Linkedin. El proceso sugerido es: \n",
    "\n",
    "1. Definir fuente de datos y viabilidad de la extraccion de datos con Web-scrapping\n",
    "2. Definir atributos relevantes de las vacantes a extraer para armar la estructura del dataframe\n",
    "3. Asegurate de guardar todos los datos de vacantes en un dataframe `vacantes_df`\n",
    "\n",
    "**Ten en cuenta, que los atributos a escoger de las vacantes deben de alguna manera permitirte hacer match con la data de las personas que te fue otorgada en el paso anterior**.\n",
    "\n",
    "Es important anotar que solo es preciso que construyas un flujo que te permita guardar los datos en un dataframe, NO es necesario montar una base de datos SQL ni nada similar.\n",
    "\n",
    "Aquí te dejamos algunos ejemplos de procesos de extraccion de vacantes de empleo de algunos portales: \n",
    "\n",
    "* [Usando Selenium o Scrapy](https://towardsdatascience.com/when-job-hunting-meets-data-science-part-1-e8f64867d8c)\n",
    "* [Otro caso de uso con Scrapy](https://towardsdatascience.com/automate-your-job-search-with-python-and-github-actions-1dc818844c0)\n",
    "* [Automatic job search with python](https://towardsdatascience.com/automating-my-job-search-with-python-ee2b465c6a8f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-165d8896-3cd5-475b-9fe2-5893b9736374",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# funciones para realizar la busqueda de los empleos\n",
    "\n",
    "## Buscador del trabajo se realizò en linkedin\n",
    "\n",
    "def buscador(job_title,location=\"colombia\"):\n",
    "    temp =\"https://co.linkedin.com/jobs/search?keywords={}&location={}&geoId=102361989&trk=public_jobs_jobs-search-bar_search-submit\"\n",
    "    url = temp.format(job_title,location)\n",
    "    return url\n",
    "\n",
    "## extraciòn de la informacion relevante\n",
    "## posicion: trabajo que busca\n",
    "## empresa. empresa que publica el trabajo\n",
    "## caracteristicas del trabajo\n",
    "\n",
    "def info_trabajo(url):\n",
    "    request=requests.get(url)\n",
    "    soup= BeautifulSoup(request.text,\"html.parser\")\n",
    "    cards= soup.find_all('a','base-card__full-link')\n",
    "    posicion,empresa,caracteristicas=[],[],[]\n",
    "    for i in range(len(cards)):\n",
    "        posicion.append(soup.find_all('div', {'class' : 'base-search-card__info'})[i].h3.text.strip())\n",
    "        empresa.append(soup.find_all('div', {'class' : 'base-search-card__info'})[i].h4.text.strip())\n",
    "        caracteristicas=soup.find_all('div', {'class' : 'base-search-card__info'})[i].p.text.strip()\n",
    "    matriz_trabajo=pd.DataFrame()\n",
    "    matriz_trabajo[\"trabajo\"]=posicion\n",
    "    matriz_trabajo[\"empresa\"]=empresa\n",
    "    matriz_trabajo[\"caracteristicas\"]=caracteristicas\n",
    "    return matriz_trabajo\n",
    "\n",
    "# creo un data frame para realizar las busquedas de trabajo\n",
    "busquedas=[]\n",
    "usuario=[]\n",
    "ingles=[]\n",
    "for n,m in zip(personas_df.anonymous_user,personas_df.nivel_de_ingles):\n",
    "    for i in personas_df.puestos_postulandose:\n",
    "        try:\n",
    "                jobs=i\n",
    "                jobs=jobs.replace(\"]\",\" \")\n",
    "                jobs=jobs.replace(\"[\",\" \")\n",
    "                jobs=jobs.split(\",\")\n",
    "\n",
    "                for t in jobs:\n",
    "                    busquedas.append(t)\n",
    "                    usuario.append(n)\n",
    "                    ingles.append(m)\n",
    "\n",
    "        except:\n",
    "            busquedas.append(\"no trabajo\") \n",
    "            usuario.append(n)\n",
    "            ingles.append(m)\n",
    "busqueda=pd.concat([pd.DataFrame(busquedas,columns=[\"busqueda\"]),pd.DataFrame(ingles,columns=[\"ingles\"]),\n",
    "                    pd.DataFrame(usuario,columns=[\"usuario\"])],axis=1)\n",
    "\n",
    "# Uso también el arry de subsector, por lo que se puede ver tiene palabras claves para realizar busquedas de trabajo \n",
    "\n",
    "sub_areas=[]\n",
    "usuario=[]\n",
    "ingles=[]\n",
    "for n,m in zip(personas_df.anonymous_user,personas_df.nivel_de_ingles):\n",
    "    for j in personas_df.subareas_trabajo:\n",
    "        try:\n",
    "                sub=j\n",
    "                sub=sub.replace(\"[\",\" \")\n",
    "                sub=sub.replace(\"]\",\" \") \n",
    "                sub=sub.split(\",\")\n",
    "                for t in sub:\n",
    "                    sub_areas.append(t)\n",
    "                    usuario.append(n)\n",
    "                    ingles.append(m)\n",
    "        except:\n",
    "            sub_areas.append(\"no trabajo\") \n",
    "            usuario.append(n)\n",
    "            ingles.append(m)\n",
    "sub_area=pd.concat([pd.DataFrame(sub_areas,columns=[\"busqueda\"]),pd.DataFrame(ingles,columns=[\"ingles\"]),\n",
    "                    pd.DataFrame(usuario,columns=[\"usuario\"])],axis=1) \n",
    "\n",
    "# genero listas con valores unicos de cada área de trabajo y sub sector, pensando que existen muchas personas que buscan el mismo \n",
    "# empleo y por lo tanto no es necesario hacer una busqueda por personas\n",
    "\n",
    "busquedas_f=busqueda.busqueda.unique()\n",
    "sub_area_f=sub_area.busqueda.unique()\n",
    "\n",
    "# crea la base de trabajos buscados, esta base se realiza con base en los trabajos que los usuarios estás buscando\n",
    "\n",
    "def compilador(data):\n",
    "    vaca_df=pd.DataFrame()\n",
    "    j=0\n",
    "    for i in data:\n",
    "        one=info_trabajo(buscador(i))\n",
    "        one[\"trabajo_buscado\"]=i\n",
    "        j=j+1\n",
    "        print(j)\n",
    "        vaca_df=pd.concat([vaca_df,one],ignore_index=True)\n",
    "    return vaca_df\n",
    "\n",
    "vacantes_df_2=compilador(sub_area_f)\n",
    "vacantes_df_1=compilador(busquedas_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-4b4f38db-a67c-45ad-a979-c64099479bfa",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Fase 2: Construcción y ejecución del modelo\n",
    "\n",
    "En esta segunda parte vas a construir el sistema de generacion de recomendaciones dados los dos dataframes: `personas_df` y `vacantes_df`. \n",
    "\n",
    "1. Como primera iteración podemos pensar en que una vacante es relevante para una persona si el titulo de la vacante es cercano a alguno de los trabajos incluidos en el campo `puestos_postulandose` de la persona en cuestion. Esta cercanía se puede calcular por medio de un algoritmo de match semántico con un embedding o por medio de una distancia levenstein entre cadenas de texto. \n",
    "\n",
    "* [¿Qué es la distancia de Levenstein?](https://es.wikipedia.org/wiki/Distancia_de_Levenshtein)\n",
    "* [¿Que es el match semántico?](https://tfhub.dev/google/universal-sentence-encoder/1)\n",
    "\n",
    "2. Si podemos extraer el nivel de ingles de las vacantes podemos hacer un filtro para que solo se le recomiende a la persona vacantes para las cuales su nivel de ingles es suficiente. \n",
    "\n",
    "Con base en las dos ideas anteriores, construye un algoritmo que permita recomendarle a cada persona las 5 vacantes que son mas afines según las variables `puestos_postulandose` y `nivel_de_ingles`. \n",
    "\n",
    "Puedes revisar el compendio general de tecnicas para similitud semántica en este [articulo](https://medium.com/@adriensieg/text-similarities-da019229c894) \n",
    "\n",
    "\n",
    "Como armarías las recomendaciones con todas las ideas y sugerencias presentadas ? deja tu codigo listo para ejecucion en el siguiente bloque: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-76c538d2-b3b7-4e4f-ba6f-2b50939c34fd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1628567509874,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# funcion para obtener la distancia de levenshtein y coseno \n",
    "\n",
    "def levenshtein(seq1, seq2):\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )          \n",
    "    return (1-(matrix[size_x - 1, size_y - 1]/max(len(seq1),len(seq2))))\n",
    "\n",
    "def coseno(data):\n",
    "    list=[]\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    for i,j in zip(data.trabajo,data.trabajo_buscado):\n",
    "        palabras=[i.lower(),j.lower().replace('\"',\"\")]\n",
    "        cuenta_vector = CountVectorizer(stop_words='spanish')\n",
    "        cuenta_vector = CountVectorizer()\n",
    "        matrix = cuenta_vector.fit_transform(palabras)\n",
    "        matrix_fin = matrix.todense()\n",
    "        df = pd.DataFrame(matrix_fin, \n",
    "                  columns=cuenta_vector.get_feature_names(), \n",
    "                  index=['palabra1', 'palabra2'])\n",
    "        list.append(cosine_similarity(df, df)[1,0])\n",
    "    data[\"dist_cosine\"]=list   \n",
    "    return(data)\n",
    "\n",
    "# una funcional adicional para obeterne la distancia\n",
    "def distancia(data):\n",
    "    distan=[]\n",
    "    for i,y in zip(data.trabajo,data.trabajo_buscado):\n",
    "        dist=levenshtein(i.lower(),y.lower().replace('\"',\"\"))\n",
    "        distan.append(dist)\n",
    "    data[\"distancia\"]=distan\n",
    "    return(data)\n",
    "\n",
    "# bases finales para el algortimo\n",
    "\n",
    "dist_1=distancia(vacantes_df_1)\n",
    "dist_2=distancia(vacantes_df_2)\n",
    "\n",
    "dist_1=coseno(dist_1)\n",
    "dist_2=coseno(dist_2)\n",
    "\n",
    "a=busqueda.merge(dist_1,left_on=\"busqueda\",right_on=\"trabajo_buscado\",how=\"left\")\n",
    "b=sub_area.merge(dist_2,left_on=\"busqueda\",right_on=\"trabajo_buscado\",how=\"left\")\n",
    "\n",
    "a[\"ponderada\"]=(a[\"distancia\"]+a[\"dist_cosine\"])/2\n",
    "b[\"ponderada\"]=(b[\"distancia\"]+b[\"dist_cosine\"])/2\n",
    "\n",
    "# funcion para determinar si hay dexripcion del nivel de inlges\n",
    "\n",
    "def nivel_ingles(data):\n",
    "    ingles=[]\n",
    "    for i in data.caracteristicas:\n",
    "        try:\n",
    "            if \"ingles\" in i:\n",
    "                ingles.append(i)\n",
    "            else: ingles.append(\"no\")    \n",
    "        except:ingles.append(\"no\") \n",
    "    data[\"filtro_ingles\"]=ingles\n",
    "    return(data)\n",
    "\n",
    "# Recomendacion\n",
    "\n",
    "def recomendacion(data1=a,data2=b):\n",
    "    ingles_a=nivel_ingles(data1)\n",
    "    ingles_b=nivel_ingles(data2)\n",
    "    ingles=pd.concat([ingles_a,ingles_b],axis=0)\n",
    "    filtro_comp=[]\n",
    "    if ingles[ingles[\"filtro_ingles\"] !=\"no\"].shape[0] !=0:\n",
    "        ingles=ingles[ingles[\"filtro_ingles\"] !=\"no\"]\n",
    "        for i,j in zip(inlges.filtro_ingles,ingles.ingles):\n",
    "            if  j==\"nan\":\n",
    "                filtro_comp.append(\"no\")\n",
    "            else: \n",
    "                if j in i:\n",
    "                    filtro_comp.append(\"yes\")\n",
    "        ingles=ingles[\"filtro_com\"]=  filtro_comp\n",
    "        ingles=ingles[[\"filtro_com\"]==\"yes\"]\n",
    "        data=ingles.sort_values('ponderada',ascending = False).groupby('usuario').head(5)   \n",
    "    else:\n",
    "        data=ingles.sort_values('ponderada',ascending = False).groupby('usuario').head(5)\n",
    "    return(data) \n",
    "\n",
    "recomendacion(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-7e0a9b94-eb70-465d-b88c-2b1909bf64e3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Hazlo mejor por ti mismo !\n",
    "\n",
    "¿Cómo podrías generar mejores recomendaciones? ¿que técnicas usarias para procesar variables de texto ? Danos tu mejor idea e inspiracion en esta parte final ideando un sistema de recomendaciones de vacantes espectacular, que sea mejor a todo lo presentado anteriormente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-48343e14-2501-478a-9453-6fef1dd7c71d",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# primero agregaria otras caracteristicas a los datos, como habilidades del candidato, tal ves y esto puede ser loco \n",
    "# pero agregaria tal vez pruebas para verificar conocimientos tecnicos, las vacantes usualmente piden cosas muy precisas\n",
    "# por lo que puntuciones de pruebas pueden ser de gran ayuda y también con la ayuda de las empresas pues son quienes fialmente \n",
    "# saben que buscan puntualmente en las vacantes.\n",
    "\n",
    "# frente a el modelado primero trataría de crear diccionarios donde pudiera generar sinonimos de palabras desde su significado, muchas veces el nombre de los cargos \n",
    "# los nombre de la vacantes no dicen mucho de las mismas, por lo tanto la descripción del cargo  toma importancia para entender si\n",
    "# por ejemplo muchas veces los cargos de la empresas no son equivalentes dentro de los cargo que uno busca, un cargo en reporting \n",
    "# puede significar un analista de datos o un cientifico de datos o simplmente alguien operativo con concocimientos en querys\n",
    "# por lo que la descripción del cargo más la deficinicón de los diferentes puesto puede lograr un macth mucho más aproximado\n",
    "\n",
    "# finalmente dado que las empresas ya tienen un esquema o candidato objetivo despues de hacer un match de texto aplicar claificación para determinar\n",
    "# de entrada cual puede ser la probabilidad de seleeción de ese usuario en un puesto X, con esto no solo se le recomendaran los cargos\n",
    "# a los que el aplico sino que además se tendrpa de alguna forma una probabilidad real para el usuario de ajustarse a la vancante\n",
    "# con lo que el usuario puede tener una mejor decisición sobre que es lo mejor para el"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ae6eb7be-f8e0-4cb7-81fd-2db19d09c955' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "5e030eaf-e332-437b-8225-4ca6353f3675",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
